{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Load a subset of the 20 Newsgroups dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "documents = newsgroups.data\n",
    "\n",
    "# Check the first document\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(doc):\n",
    "    # Tokenize the document\n",
    "    tokens = word_tokenize(doc.lower())\n",
    "    # Remove stopwords and non-alphabetic words\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to each document\n",
    "processed_documents = [preprocess(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary representation of the documents\n",
    "dictionary = corpora.Dictionary(processed_documents)\n",
    "\n",
    "# Convert documents into the bag-of-words format\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LDA (Latent Dirichlet Allocation) for topic modeling\n",
    "num_topics = 10\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=50)\n",
    "\n",
    "# Print the topics in a more human-readable format\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f\"\\nTopic {idx + 1}:\")\n",
    "    print(\"=\"*30)\n",
    "    words = topic.split(\" + \")\n",
    "    for word in words:\n",
    "        weight, term = word.split(\"*\")\n",
    "        print(f\"{term.strip()} ({float(weight):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics using pyLDAvis\n",
    "vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mma865",
   "language": "python",
   "name": "mma865"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
